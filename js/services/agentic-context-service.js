/**
 * Sistema de Contexto Ag√©ntico para PlumAI
 * La IA decide qu√© contexto necesita en lugar de enviar todo
 *
 * FLUJO DE 2 PASOS:
 * 1. Request 1: IA analiza tarea y decide qu√© contexto necesita
 * 2. Request 2: Sistema env√≠a SOLO el contexto solicitado
 */

window.agenticContextService = {

    // ============================================
    // SISTEMA DE INVENTARIO DE CONTEXTO
    // ============================================

    /**
     * Construye un inventario ligero del contexto disponible
     * Solo nombres/t√≠tulos, NO contenido completo
     */
    buildContextInventory(chapterId = null) {
        const projectStore = Alpine.store('project');
        if (!projectStore) return null;

        const inventory = {
            project: {
                title: projectStore.projectInfo.title,
                author: projectStore.projectInfo.author,
                genre: projectStore.projectInfo.genre
            },
            availableCharacters: projectStore.characters.map(c => ({
                name: c.name,
                role: c.role
            })),
            availableLocations: projectStore.locations.map(l => ({
                name: l.name,
                type: l.type
            })),
            availableScenes: projectStore.scenes.map(s => ({
                name: s.name
            })),
            availableLore: projectStore.loreEntries.map(l => ({
                title: l.title,
                category: l.category
            })),
            availableTimeline: projectStore.timeline.map(t => ({
                title: t.title,
                date: t.date
            })),
            currentChapterInfo: null,
            previousChaptersCount: 0
        };

        // Info del cap√≠tulo actual (sin contenido completo)
        if (chapterId) {
            const chapter = projectStore.getChapter(chapterId);
            if (chapter) {
                inventory.currentChapterInfo = {
                    title: chapter.title,
                    number: chapter.number,
                    wordCount: chapter.wordCount
                };

                // Contar cap√≠tulos anteriores disponibles
                inventory.previousChaptersCount = projectStore.chapters
                    .filter(c => c.number < chapter.number)
                    .length;
            }
        }

        return inventory;
    },

    // ============================================
    // PASO 1: AN√ÅLISIS DE NECESIDADES
    // ============================================

    /**
     * Prompt para que la IA analice qu√© contexto necesita
     */
    buildContextAnalysisPrompt(mode, userInput, inventory, selectedText = null) {
        const modeConfig = window.aiService.assistantModes[mode];

        let prompt = `# AN√ÅLISIS DE CONTEXTO NECESARIO

Eres un asistente que debe analizar una tarea de escritura y determinar qu√© contexto espec√≠fico necesitas para completarla de manera √≥ptima.

## TAREA DEL USUARIO
**Modo**: ${modeConfig.name}
**Instrucci√≥n**: ${userInput}
`;

        if (selectedText) {
            prompt += `**Texto seleccionado**: ${selectedText.substring(0, 500)}${selectedText.length > 500 ? '...' : ''}\n`;
        }

        prompt += `\n## PROYECTO: ${inventory.project.title}
**G√©nero**: ${inventory.project.genre || 'No especificado'}

## CONTEXTO DISPONIBLE

### Personajes disponibles (${inventory.availableCharacters.length}):
${inventory.availableCharacters.map(c => `- ${c.name} (${c.role})`).join('\n')}

### Locaciones disponibles (${inventory.availableLocations.length}):
${inventory.availableLocations.map(l => `- ${l.name} (${l.type})`).join('\n')}

### Escenas disponibles (${inventory.availableScenes.length}):
${inventory.availableScenes.map(s => `- ${s.name}`).join('\n')}

### Lore disponible (${inventory.availableLore.length}):
${inventory.availableLore.map(l => `- ${l.title} (${l.category})`).join('\n')}

### Timeline disponible (${inventory.availableTimeline.length}):
${inventory.availableTimeline.map(t => `- ${t.title} (${t.date})`).join('\n')}
`;

        if (inventory.currentChapterInfo) {
            prompt += `\n### Cap√≠tulo actual:
- N√∫mero: ${inventory.currentChapterInfo.number}
- T√≠tulo: ${inventory.currentChapterInfo.title}
- Palabras: ${inventory.currentChapterInfo.wordCount}

### Cap√≠tulos anteriores disponibles: ${inventory.previousChaptersCount}
`;
        }

        prompt += `\n---

## INSTRUCCIONES

Analiza la tarea y responde √öNICAMENTE con un JSON que especifique qu√© contexto necesitas.

**Formato de respuesta (JSON estricto):**
\`\`\`json
{
  "contextNeeded": {
    "characters": ["nombre1", "nombre2"] o [] si no necesitas ninguno o ["all"] para todos,
    "locations": ["nombre1"] o [] o ["all"],
    "scenes": ["nombre1"] o [] o ["all"],
    "lore": ["t√≠tulo1", "t√≠tulo2"] o [] o ["all"],
    "timeline": ["t√≠tulo1"] o [] o ["all"],
    "currentChapter": true o false (si necesitas el contenido completo del cap√≠tulo actual),
    "previousChapters": 0-${inventory.previousChaptersCount} (cu√°ntos cap√≠tulos anteriores necesitas),
    "reasoning": "breve explicaci√≥n de por qu√© necesitas este contexto"
  }
}
\`\`\`

**IMPORTANTE**:
- S√© SELECTIVO: Solo pide lo que realmente necesitas para la tarea
- Si solo necesitas algunos personajes espec√≠ficos mencionados en el texto, pide solo esos
- No pidas "all" a menos que genuinamente necesites toda esa categor√≠a
- El objetivo es MINIMIZAR tokens mientras mantienes la calidad
- Responde SOLO con el JSON, sin texto adicional

Analiza y responde:`;

        return prompt;
    },

    /**
     * REQUEST 1: Env√≠a an√°lisis de contexto a la IA
     */
    async analyzeContextNeeds(mode, userInput, inventory, selectedText = null) {
        const provider = window.aiService.getCurrentProvider();

        // LOG: Inicio de An√°lisis Ag√©ntico (Step 1)
        if (window.plumLogger) {
            window.plumLogger.group('AGENTIC STEP 1', 'üß† An√°lisis de contexto necesario', '#00BCD4');
            window.plumLogger.info('Modo', mode);
            window.plumLogger.info('Inventario', `${inventory.availableCharacters.length} chars, ${inventory.availableLocations.length} locs, ${inventory.availableLore.length} lore`);
        }

        const analysisPrompt = this.buildContextAnalysisPrompt(mode, userInput, inventory, selectedText);

        // LOG: Prompt de an√°lisis
        if (window.plumLogger) {
            window.plumLogger.debug('Prompt enviado', `${analysisPrompt.length} chars`);
        }

        try {
            let response;

            // Usar el proveedor actual para analizar
            switch (provider.id) {
                case 'google':
                    response = await window.aiService.sendGoogleRequest(analysisPrompt);
                    break;
                case 'groq':
                    response = await window.aiService.sendGroqRequest(analysisPrompt);
                    break;
                case 'anthropic':
                    response = await window.aiService.sendAnthropicRequest(analysisPrompt);
                    break;
                case 'ollama':
                    response = await window.aiService.sendOllamaRequest(analysisPrompt);
                    break;
                default:
                    throw new Error(`Proveedor ${provider.id} no soportado para modo ag√©ntico`);
            }

            // Parsear respuesta JSON
            const jsonMatch = response.content.match(/\{[\s\S]*\}/);
            if (!jsonMatch) {
                throw new Error('La IA no devolvi√≥ un JSON v√°lido');
            }

            const contextDecision = JSON.parse(jsonMatch[0]);

            // LOG: Decisi√≥n de la IA
            if (window.plumLogger) {
                window.plumLogger.success('An√°lisis completo', 'IA decidi√≥ qu√© contexto necesita');
                window.plumLogger.groupCollapsed('DECISI√ìN', 'üéØ Contexto solicitado', '#4CAF50');
                window.plumLogger.info('Personajes', contextDecision.contextNeeded.characters);
                window.plumLogger.info('Locaciones', contextDecision.contextNeeded.locations);
                window.plumLogger.info('Escenas', contextDecision.contextNeeded.scenes);
                window.plumLogger.info('Lore', contextDecision.contextNeeded.lore);
                window.plumLogger.info('Timeline', contextDecision.contextNeeded.timeline);
                window.plumLogger.info('Cap√≠tulo actual', contextDecision.contextNeeded.currentChapter);
                window.plumLogger.info('Cap√≠tulos previos', contextDecision.contextNeeded.previousChapters);
                window.plumLogger.debug('Razonamiento', contextDecision.contextNeeded.reasoning);
                window.plumLogger.groupEnd();
                window.plumLogger.groupEnd(); // Cierra AGENTIC STEP 1
            }

            return contextDecision.contextNeeded;

        } catch (error) {
            if (window.plumLogger) {
                window.plumLogger.error('ERROR', `Error en an√°lisis: ${error.message}`);
                window.plumLogger.groupEnd();
            }
            throw error;
        }
    },

    // ============================================
    // CONSTRUCCI√ìN SELECTIVA DE CONTEXTO
    // ============================================

    /**
     * Construye SOLO el contexto solicitado por la IA
     */
    buildSelectiveContext(contextNeeds, chapterId = null) {
        const projectStore = Alpine.store('project');
        if (!projectStore) return null;

        const context = {
            project: {
                title: projectStore.projectInfo.title,
                author: projectStore.projectInfo.author,
                genre: projectStore.projectInfo.genre
            }
        };

        // Personajes selectivos
        if (contextNeeds.characters && contextNeeds.characters.length > 0) {
            if (contextNeeds.characters.includes('all')) {
                context.characters = projectStore.characters.map(c => ({
                    name: c.name,
                    role: c.role,
                    description: c.description,
                    personality: c.personality,
                    background: c.background
                }));
            } else {
                context.characters = projectStore.characters
                    .filter(c => contextNeeds.characters.includes(c.name))
                    .map(c => ({
                        name: c.name,
                        role: c.role,
                        description: c.description,
                        personality: c.personality,
                        background: c.background
                    }));
            }
        } else {
            context.characters = [];
        }

        // Locaciones selectivas
        if (contextNeeds.locations && contextNeeds.locations.length > 0) {
            if (contextNeeds.locations.includes('all')) {
                context.locations = projectStore.locations.map(l => ({
                    name: l.name,
                    type: l.type,
                    description: l.description
                }));
            } else {
                context.locations = projectStore.locations
                    .filter(l => contextNeeds.locations.includes(l.name))
                    .map(l => ({
                        name: l.name,
                        type: l.type,
                        description: l.description
                    }));
            }
        } else {
            context.locations = [];
        }

        // Escenas selectivas
        if (contextNeeds.scenes && contextNeeds.scenes.length > 0) {
            if (contextNeeds.scenes.includes('all')) {
                context.scenes = projectStore.scenes.map(s => ({
                    name: s.name,
                    description: s.description,
                    characters: s.characters || []
                }));
            } else {
                context.scenes = projectStore.scenes
                    .filter(s => contextNeeds.scenes.includes(s.name))
                    .map(s => ({
                        name: s.name,
                        description: s.description,
                        characters: s.characters || []
                    }));
            }
        } else {
            context.scenes = [];
        }

        // Lore selectivo
        if (contextNeeds.lore && contextNeeds.lore.length > 0) {
            if (contextNeeds.lore.includes('all')) {
                context.lore = projectStore.loreEntries.map(l => ({
                    title: l.title,
                    content: l.content,
                    category: l.category
                }));
            } else {
                context.lore = projectStore.loreEntries
                    .filter(l => contextNeeds.lore.includes(l.title))
                    .map(l => ({
                        title: l.title,
                        content: l.content,
                        category: l.category
                    }));
            }
        } else {
            context.lore = [];
        }

        // Timeline selectivo
        if (contextNeeds.timeline && contextNeeds.timeline.length > 0) {
            if (contextNeeds.timeline.includes('all')) {
                context.timeline = projectStore.timeline.map(t => ({
                    title: t.title,
                    date: t.date,
                    description: t.description
                }));
            } else {
                context.timeline = projectStore.timeline
                    .filter(t => contextNeeds.timeline.includes(t.title))
                    .map(t => ({
                        title: t.title,
                        date: t.date,
                        description: t.description
                    }));
            }
        } else {
            context.timeline = [];
        }

        // Cap√≠tulo actual (si solicitado)
        if (contextNeeds.currentChapter && chapterId) {
            const chapter = projectStore.getChapter(chapterId);
            if (chapter) {
                context.currentChapter = {
                    title: chapter.title,
                    number: chapter.number,
                    content: chapter.content,
                    wordCount: chapter.wordCount
                };
            }
        }

        // Cap√≠tulos anteriores (cantidad espec√≠fica)
        if (contextNeeds.previousChapters && contextNeeds.previousChapters > 0 && chapterId) {
            const chapter = projectStore.getChapter(chapterId);
            if (chapter) {
                context.previousChapters = projectStore.chapters
                    .filter(c => c.number < chapter.number)
                    .sort((a, b) => a.number - b.number)
                    .slice(-contextNeeds.previousChapters)
                    .map(c => ({
                        number: c.number,
                        title: c.title,
                        summary: c.content.substring(0, 500) + '...'
                    }));
            }
        }

        return context;
    },

    // ============================================
    // PASO 2: EJECUCI√ìN CON CONTEXTO OPTIMIZADO
    // ============================================

    /**
     * REQUEST 2: Ejecuta la tarea con el contexto selectivo
     */
    async executeWithSelectiveContext(mode, userInput, context, selectedText = null) {
        const startTime = performance.now();
        const provider = window.aiService.getCurrentProvider();

        // LOG: Inicio de Ejecuci√≥n Ag√©ntica (Step 2)
        if (window.plumLogger) {
            window.plumLogger.group('AGENTIC STEP 2', '‚ö° Ejecuci√≥n con contexto optimizado', '#4CAF50');
            const contextSize = (context.characters?.length || 0) +
                               (context.locations?.length || 0) +
                               (context.lore?.length || 0) +
                               (context.timeline?.length || 0);
            window.plumLogger.info('Contexto selectivo', `${contextSize} elementos enviados`);
            window.plumLogger.contextData('Personajes', context.characters);
            window.plumLogger.contextData('Locaciones', context.locations);
            window.plumLogger.contextData('Lore', context.lore);
            window.plumLogger.contextData('Timeline', context.timeline);
        }

        // Construir prompt final con contexto selectivo
        const prompt = window.aiService.buildPrompt(mode, userInput, context, selectedText);

        // LOG: Prompt final
        if (window.plumLogger) {
            const estimatedTokens = Math.ceil(prompt.length / 4);
            window.plumLogger.promptBuilt(prompt.length, estimatedTokens);
            window.plumLogger.promptPreview(prompt);
        }

        try {
            let response;

            switch (provider.id) {
                case 'google':
                    response = await window.aiService.sendGoogleRequest(prompt);
                    break;
                case 'groq':
                    response = await window.aiService.sendGroqRequest(prompt);
                    break;
                case 'anthropic':
                    response = await window.aiService.sendAnthropicRequest(prompt);
                    break;
                case 'ollama':
                    response = await window.aiService.sendOllamaRequest(prompt);
                    break;
                default:
                    throw new Error(`Proveedor ${provider.id} no soportado`);
            }

            // LOG: Completado
            if (window.plumLogger) {
                const totalTime = Math.round(performance.now() - startTime);
                window.plumLogger.success('AGENTIC COMPLETE', `‚è± Tiempo total: ${totalTime}ms`);
                window.plumLogger.info('Modelo usado', window.aiService.currentModel);
                if (response.usage) {
                    window.plumLogger.info('Tokens', `Usados: ${response.usage.totalTokens || response.usage.total_tokens}`);
                }
                window.plumLogger.groupEnd(); // Cierra AGENTIC STEP 2
            }

            return response;

        } catch (error) {
            if (window.plumLogger) {
                window.plumLogger.error('ERROR', error.message);
                window.plumLogger.groupEnd();
            }
            throw error;
        }
    },

    // ============================================
    // M√âTODO PRINCIPAL: FLUJO COMPLETO DE 2 PASOS
    // ============================================

    /**
     * Ejecuta el flujo ag√©ntico completo de 2 pasos (conversacional)
     * Soporta historial de mensajes para mantener contexto de conversaci√≥n
     */
    async sendAgenticConversation(mode, messages, chapterId = null) {
        const overallStart = performance.now();

        // LOG: Inicio del flujo ag√©ntico conversacional
        if (window.plumLogger) {
            window.plumLogger.separator();
            window.plumLogger.group('ü§ñ AGENTIC CONVERSATION', 'Sistema de Contexto Ag√©ntico (Conversacional)', '#00BCD4');
            window.plumLogger.info('Mensajes en historial', messages.length);
            window.plumLogger.info('Modo', mode);
        }

        try {
            // Construir prompt conversacional desde historial
            let conversationPrompt = "## HISTORIAL DE CONVERSACI√ìN\n\n";
            messages.forEach(msg => {
                const role = msg.role === 'user' ? 'Usuario' : 'Asistente';
                conversationPrompt += `**${role}:** ${msg.content}\n\n`;
            });

            // Obtener el √∫ltimo mensaje del usuario
            const lastUserMessage = messages.filter(m => m.role === 'user').pop();
            const userInput = lastUserMessage ? lastUserMessage.content : '';

            // PASO 1: Construir inventario y analizar necesidades
            const inventory = this.buildContextInventory(chapterId);
            const contextNeeds = await this.analyzeContextNeeds(mode, conversationPrompt, inventory, null);

            // PASO 2: Construir contexto selectivo y ejecutar
            const selectiveContext = this.buildSelectiveContext(contextNeeds, chapterId);

            // Ejecutar con contexto selectivo y conversaci√≥n
            const response = await this.executeConversationWithContext(mode, conversationPrompt, selectiveContext);

            // LOG: Resumen final
            if (window.plumLogger) {
                const totalTime = Math.round(performance.now() - overallStart);
                window.plumLogger.separator();
                window.plumLogger.success('FLUJO CONVERSACIONAL COMPLETO', `‚úì Proceso ag√©ntico completado en ${totalTime}ms`);
                window.plumLogger.groupEnd(); // Cierra AGENTIC CONVERSATION
                window.plumLogger.separator();
            }

            return response;

        } catch (error) {
            if (window.plumLogger) {
                window.plumLogger.error('ERROR AG√âNTICO CONVERSACIONAL', error.message);
                window.plumLogger.groupEnd();
            }
            throw error;
        }
    },

    /**
     * Ejecuta conversaci√≥n con contexto optimizado
     */
    async executeConversationWithContext(mode, conversationPrompt, context) {
        const startTime = performance.now();
        const provider = window.aiService.getCurrentProvider();

        // LOG: Inicio de Ejecuci√≥n Conversacional
        if (window.plumLogger) {
            window.plumLogger.group('CONVERSATION STEP 2', 'üí¨ Ejecuci√≥n conversacional con contexto', '#4CAF50');
            const contextSize = (context.characters?.length || 0) +
                               (context.locations?.length || 0) +
                               (context.lore?.length || 0) +
                               (context.timeline?.length || 0);
            window.plumLogger.info('Contexto selectivo', `${contextSize} elementos enviados`);
        }

        // Construir prompt conversacional con contexto
        const modeConfig = window.aiService.assistantModes[mode];

        let prompt = `# PROYECTO: ${context.project.title}\n`;
        prompt += `**G√©nero**: ${context.project.genre || 'No especificado'}\n\n`;

        // Agregar contexto relevante
        if (context.characters && context.characters.length > 0) {
            prompt += `## PERSONAJES\n`;
            context.characters.forEach(char => {
                prompt += `\n### ${char.name} (${char.role})\n`;
                if (char.description) prompt += `${char.description}\n`;
                if (char.personality) prompt += `**Personalidad**: ${char.personality}\n`;
            });
            prompt += '\n';
        }

        if (context.lore && context.lore.length > 0) {
            prompt += `## WORLDBUILDING\n`;
            context.lore.forEach(lore => {
                prompt += `- **${lore.title}**: ${lore.content.substring(0, 200)}...\n`;
            });
            prompt += '\n';
        }

        if (context.currentChapter) {
            prompt += `## CAP√çTULO ACTUAL: ${context.currentChapter.title}\n`;
            prompt += `${context.currentChapter.content}\n\n`;
        }

        // Agregar conversaci√≥n
        prompt += `---\n\n${conversationPrompt}\n\n`;

        // Agregar instrucci√≥n del modo
        prompt += `**Modo**: ${modeConfig.name}\n`;
        prompt += `**Tarea**: ${modeConfig.systemPrompt}\n\n`;
        prompt += `Responde al √∫ltimo mensaje del usuario manteniendo el contexto de toda la conversaci√≥n.`;

        // LOG: Prompt final
        if (window.plumLogger) {
            const estimatedTokens = Math.ceil(prompt.length / 4);
            window.plumLogger.promptBuilt(prompt.length, estimatedTokens);
        }

        try {
            let response;

            switch (provider.id) {
                case 'google':
                    response = await window.aiService.sendGoogleRequest(prompt);
                    break;
                case 'groq':
                    response = await window.aiService.sendGroqRequest(prompt);
                    break;
                case 'anthropic':
                    response = await window.aiService.sendAnthropicRequest(prompt);
                    break;
                case 'ollama':
                    response = await window.aiService.sendOllamaRequest(prompt);
                    break;
                default:
                    throw new Error(`Proveedor ${provider.id} no soportado`);
            }

            // LOG: Completado
            if (window.plumLogger) {
                const totalTime = Math.round(performance.now() - startTime);
                window.plumLogger.success('CONVERSATION COMPLETE', `‚è± Tiempo total: ${totalTime}ms`);
                window.plumLogger.groupEnd();
            }

            return response;

        } catch (error) {
            if (window.plumLogger) {
                window.plumLogger.error('ERROR', error.message);
                window.plumLogger.groupEnd();
            }
            throw error;
        }
    },

    /**
     * Ejecuta el flujo ag√©ntico completo de 2 pasos (mensaje √∫nico)
     */
    async sendAgenticRequest(mode, userInput, chapterId = null, selectedText = null) {
        const overallStart = performance.now();

        // LOG: Inicio del flujo ag√©ntico
        if (window.plumLogger) {
            window.plumLogger.separator();
            window.plumLogger.group('ü§ñ AGENTIC AI', 'Sistema de Contexto Ag√©ntico', '#00BCD4');
            window.plumLogger.info('Usuario', userInput);
            window.plumLogger.info('Modo', mode);
        }

        try {
            // PASO 1: Construir inventario y analizar necesidades
            const inventory = this.buildContextInventory(chapterId);
            const contextNeeds = await this.analyzeContextNeeds(mode, userInput, inventory, selectedText);

            // PASO 2: Construir contexto selectivo y ejecutar
            const selectiveContext = this.buildSelectiveContext(contextNeeds, chapterId);
            const response = await this.executeWithSelectiveContext(mode, userInput, selectiveContext, selectedText);

            // LOG: Resumen final
            if (window.plumLogger) {
                const totalTime = Math.round(performance.now() - overallStart);
                window.plumLogger.separator();
                window.plumLogger.success('FLUJO COMPLETO', `‚úì Proceso ag√©ntico completado en ${totalTime}ms`);
                window.plumLogger.groupEnd(); // Cierra AGENTIC AI
                window.plumLogger.separator();
            }

            return response;

        } catch (error) {
            if (window.plumLogger) {
                window.plumLogger.error('ERROR AG√âNTICO', error.message);
                window.plumLogger.groupEnd();
            }
            throw error;
        }
    }
};
